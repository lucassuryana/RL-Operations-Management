{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def seat_time_list(tot_seat,tot_day):\n",
    "    '''\n",
    "    Function to create a list based on total days and total seats available\n",
    "\n",
    "    Args:\n",
    "    tot_seat (int) -> total passenger seats the full electric flight could carry\n",
    "    tot_day (int) -> total days since passenger seats can be bought before the flight\n",
    "\n",
    "    Return:\n",
    "    list_seat, list_day\n",
    "    '''\n",
    "\n",
    "    list_seat = list(range(0,tot_seat+1))\n",
    "    list_day = list(range(0,tot_day+1))\n",
    "\n",
    "    return list_seat, list_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_reward_matrix(remain_seat, remain_day):\n",
    "    '''\n",
    "    Function to calculate the expected reward matrix\n",
    "\n",
    "    Args:\n",
    "    remain_seat (int) -> total remaining available seats\n",
    "    remain_day (int) -> total remaining days until the flight\n",
    "\n",
    "    Return:\n",
    "    total_reward (float) -> total expected reward\n",
    "    '''\n",
    "\n",
    "    reward_matrix = np.zeros((11,26))\n",
    "\n",
    "    for seat in range(1,11):\n",
    "        for day in range(1,26):\n",
    "            \n",
    "            policy = np.zeros((1,3))[0]\n",
    "            for num in range(0,3):\n",
    "                if num == 0:\n",
    "                    # policy 1\n",
    "                    policy[num] = reward_matrix[seat,day] = 0.4 * (3000 + reward_matrix[seat-1, day-1]) \\\n",
    "                        + 0.3 * (reward_matrix[seat, day-1]) + 0.3 * (reward_matrix[seat, day-1])\n",
    "                elif num == 1:\n",
    "                    # policy 2\n",
    "                    policy[num] = reward_matrix[seat,day] = 0.4 * (3000 + reward_matrix[seat-1, day-1]) \\\n",
    "                        + 0.3 * (2000 + reward_matrix[seat-1, day-1]) + 0.3 * (reward_matrix[seat, day-1])\n",
    "                else:\n",
    "                    # policy 3\n",
    "                    policy[num] = reward_matrix[seat,day] = 0.4 * (3000 + reward_matrix[seat-1, day-1]) \\\n",
    "                        + 0.3 * (2000 + reward_matrix[seat-1, day-1]) + 0.3 * (1000 + reward_matrix[seat-1, day-1])\n",
    "\n",
    "            # get policy that will maximize the expected reward\n",
    "            index = np.where(policy == max(policy))\n",
    "            opt_policy = index[0][0]\n",
    "\n",
    "            opt_reward = policy[opt_policy]\n",
    "            reward_matrix[seat, day] = opt_reward\n",
    "    \n",
    "    return print(\"Expected reward value V(%s,%s) is %s\" % (remain_seat, remain_day, reward_matrix[remain_seat, remain_day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected reward value V(10,25) is 28769.208120707823\n"
     ]
    }
   ],
   "source": [
    "exp_reward_matrix(10,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "942f701b2df79ca4a1aae4324dbf019e14a586254b6da93e38e747ff79b81825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
